@BOOK{van2000empirical,
  title     = "Empirical Processes in {M-Estimation}",
  author    = "van de Geer, Sara",
  publisher = "Cambridge University Press",
  year      =  2000,
}


@article{van2014additive,
  title={The additive model with different smoothness for the components},
  author={van de Geer, Sara and Muro, Alan},
  journal={arXiv preprint arXiv:1405.6584},
  year={2014}
}

@ARTICLE{arlot2010survey,
	title     = "A survey of cross-validation procedures for model selection",
	author    = "Arlot, Sylvain and Celisse, Alain",
	abstract  = "Project Euclid - mathematics and statistics online",
	journal   = "Stat. Surv.",
	publisher = "The author, under a Creative Commons Attribution License",
	volume    =  4,
	pages     = "40--79",
	year      =  2010,
	keywords  = "Model selection; cross-validation; leave-one-out",
	language  = "en"
}


@ARTICLE{Van_der_Laan2003-ei,
	title   = "Unified {Cross-Validation} Methodology For Selection Among
	Estimators and a General {Cross-Validated} Adaptive {Epsilon-Net}
	Estimator: Finite Sample Oracle Inequalities and Examples",
	author  = "van der Laan, Mark J and Dudoit, Sandrine",
	journal = "U.C. Berkeley Division of Biostatistics Working Paper Series",
	year    =  2003
}



@ARTICLE{Van_der_Laan2004-bp,
	title    = "Asymptotic optimality of likelihood-based cross-validation",
	author   = "van der Laan, Mark J and Dudoit, Sandrine and Keles, Sunduz",
	abstract = "Likelihood-based cross-validation is a statistical tool for
	selecting a density estimate based on n i.i.d. observations from
	the true density among a collection of candidate density
	estimators. General examples are the selection of a model
	indexing a maximum likelihood estimator, and the selection of a
	bandwidth indexing a nonparametric (e.g. kernel) density
	estimator. In this article, we establish a finite sample result
	for a general class of likelihood-based cross-validation
	procedures (as indexed by the type of sample splitting used, e.g.
	V-fold cross-validation). This result implies that the
	cross-validation selector performs asymptotically as well (w.r.t.
	to the Kullback-Leibler distance to the true density) as a
	benchmark model selector which is optimal for each given dataset
	and depends on the true density. Crucial conditions of our
	theorem are that the size of the validation sample converges to
	infinity, which excludes leave-one-out cross-validation, and that
	the candidate density estimates are bounded away from zero and
	infinity. We illustrate these asymptotic results and the
	practical performance of likelihood-based cross-validation for
	the purpose of bandwidth selection with a simulation study.
	Moreover, we use likelihood-based cross-validation in the context
	of regulatory motif detection in DNA sequences.",
	journal  = "Stat. Appl. Genet. Mol. Biol.",
	volume   =  3,
	pages    = "1--23",
	year     =  2004,
	language = "en"
}


@article{lecue2012oracle,
  title={Oracle inequalities for cross-validation type procedures},
  author={Lecu{\'e}, Guillaume and Mitchell, Charles},
  journal={Electronic Journal of Statistics},
  volume={6},
  pages={1803--1837},
  year={2012},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}


@BOOK{gyorfi2002distribution,
	title     = "A Distribution-Free Theory of Nonparametric Regression",
	author    = "Gy{\"o}rfi, L{\'a}szl{\'o} and Kohler, Michael and Krzyzak, Adam
	and Walk, Harro",
	publisher = "Springer-Verlag New York",
	series    = "Springer Series in Statistics",
	edition   =  1,
	year      =  2002
}


@article{wegkamp2003model,
  title={Model selection in nonparametric regression},
  author={Wegkamp, Marten},
  journal={Annals of Statistics},
  pages={252--273},
  year={2003},
  publisher={JSTOR}
}

@article{golub1979generalized,
  title={Generalized cross-validation as a method for choosing a good ridge parameter},
  author={Golub, Gene H and Heath, Michael and Wahba, Grace},
  journal={Technometrics},
  volume={21},
  number={2},
  pages={215--223},
  year={1979},
  publisher={Taylor \& Francis}
}

@article{chetverikov2016cross,
  title={On cross-validated Lasso},
  author        = "Chetverikov, Denis and Liao, Zhipeng and Chernozhukov, Victor",
  journal={arXiv preprint arXiv:1605.02214},
  year={2016}
}

@article{chatterjee2015prediction,
  title={Prediction error of cross-validated Lasso},
  author={Chatterjee, Sourav and Jafarov, Jafar},
  journal={arXiv preprint arXiv:1502.06291},
  year={2015},
}

@article{zou2003regression,
  title={Regression shrinkage and selection via the elastic net},
  author={Zou, Hui and Hastie, Trevor},
  journal={Journal of the Royal Statistical Society: Series B.},
  volume={67},
  pages={301--320},
  year={2003}
}

@article{simon2013sparse,
  title={A sparse-group lasso},
  author={Simon, Noah and Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  journal={Journal of Computational and Graphical Statistics},
  volume={22},
  number={2},
  pages={231--245},
  year={2013},
  publisher={Taylor \& Francis Group}
}
@article{bengio2000gradient,
  title={Gradient-based optimization of hyperparameters},
  author={Bengio, Yoshua},
  journal={Neural computation},
  volume={12},
  number={8},
  pages={1889--1900},
  year={2000},
  publisher={MIT Press}
}

@INCOLLECTION{foo2008efficient,
  title     = "Efficient multiple hyperparameter learning for log-linear models",
  booktitle = "Advances in Neural Information Processing Systems 20",
  author    = "Foo, Chuan-Sheng and Do, Chuong B and Ng, Andrew Y",
  editor    = "Platt, J C and Koller, D and Singer, Y and Roweis, S T",
  publisher = "Curran Associates, Inc.",
  pages     = "377--384",
  year      =  2008
}


@INCOLLECTION{snoek2012practical,
  title     = "Practical Bayesian Optimization of Machine Learning Algorithms",
  booktitle = "Advances in Neural Information Processing Systems 25",
  author    = "Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P",
  editor    = "Pereira, F and Burges, C J C and Bottou, L and Weinberger, K Q",
  publisher = "Curran Associates, Inc.",
  pages     = "2951--2959",
  year      =  2012
}


@book{de1978practical,
  title={A practical guide to splines},
  author={De Boor, Carl and De Boor, Carl and Math{\'e}maticien, Etats-Unis and De Boor, Carl and De Boor, Carl},
  volume={27},
  year={1978},
  publisher={Springer-Verlag New York}
}

@book{wahba1990spline,
  title={Spline models for observational data},
  author={Wahba, Grace},
  volume={59},
  year={1990},
  publisher={Siam}
}

@article{green1994nonparametric,
  title={Nonparametric regression and generalized linear models, Vol. 58 of},
  author={Green, PJ and Silverman, BW},
  journal={Monographs on Statistics and Applied Probability},
  year={1994}
}

@BOOK{buhlmann2011statistics,
  title     = "Statistics for {High-Dimensional} Data: Methods, Theory and
               Applications",
  author    = "B{\"u}hlmann, Peter and van de Geer, Sara",
  publisher = "Springer-Verlag Berlin Heidelberg",
  series    = "Springer Series in Statistics",
  edition   =  1,
  year      =  2011
}


@Article{Buldygin1980,
author="Buldygin, V. V.
and Kozachenko, Yu. V.",
title="Sub-Gaussian random variables",
journal="Ukrainian Mathematical Journal",
year="1980",
volume="32",
number="6",
pages="483--489",
issn="1573-9376",
doi="10.1007/BF01087176",
url="http://dx.doi.org/10.1007/BF01087176"
}

@book{stromberg1994probability,
  title={Probability For Analysts},
  author={Stromberg, K.},
  isbn={9780412041716},
  lccn={lc93021433},
  series={Chapman \& Hall/CRC Probability Series},
  url={https://books.google.com/books?id=gQaz79fv6QUC},
  year={1994},
  publisher={Taylor \& Francis}
}

@article{barron1999risk,
  title={Risk bounds for model selection via penalization},
  author={Barron, Andrew and Birg{\'e}, Lucien and Massart, Pascal},
  journal={Probability theory and related fields},
  volume={113},
  number={3},
  pages={301--413},
  year={1999},
  publisher={Springer}
}



@ARTICLE{tibshirani1996regression,
  title     = "Regression Shrinkage and Selection via the Lasso",
  author    = "Tibshirani, Robert",
  abstract  = "We propose a new method for estimation in linear models. The
               `lasso' minimizes the residual sum of squares subject to the sum
               of the absolute value of the coefficients being less than a
               constant. Because of the nature of this constraint it tends to
               produce some coefficients that are exactly 0 and hence gives
               interpretable models. Our simulation studies suggest that the
               lasso enjoys some of the favourable properties of both subset
               selection and ridge regression. It produces interpretable models
               like subset selection and exhibits the stability of ridge
               regression. There is also an interesting relationship with
               recent work in adaptive function estimation by Donoho and
               Johnstone. The lasso idea is quite general and can be applied in
               a variety of statistical models: extensions to generalized
               regression models and tree-based models are briefly described.",
  journal   = "J. R. Stat. Soc. Series B Stat. Methodol.",
  publisher = "[Royal Statistical Society, Wiley]",
  volume    =  58,
  number    =  1,
  pages     = "267--288",
  year      =  1996
}

@article{yuan2006model,
  title     = "Model selection and estimation in regression with grouped
               variables",
  author    = "Yuan, Ming and Lin, Yi",
  journal   = "J. R. Stat. Soc. Series B Stat. Methodol.",
  volume    =  68,
  number    =  1,
  pages     = "49--67",
  year      =  2006
}


@article{kunapuli2008bilevel,
  title={Bilevel model selection for support vector machines},
  author={Kunapuli, Gautam and Bennett, K and Hu, Jing and Pang, Jong-Shi},
  journal={Manuscript, Department of Mathematical Sciences, Rensselaer Polytechnic Institute (March 2007)},
  year={2008}
}

@article{efron2004least,
  title={Least angle regression},
  author={Efron, Bradley and Hastie, Trevor and Johnstone, Iain and Tibshirani, Robert and others},
  journal={The Annals of statistics},
  volume={32},
  number={2},
  pages={407--499},
  year={2004},
  publisher={Institute of Mathematical Statistics}
}


@book{tibshirani2011solution,
  title={The solution path of the generalized lasso},
  author={Tibshirani, Ryan Joseph and Taylor, Jonathan E and Candes, Emmanuel Jean and Hastie, Trevor},
  year={2011},
  publisher={Stanford University}
}


@article{li1987asymptotic,
  title={Asymptotic Optimality for {C$_{p}$}, {C$_{L}$},
  {Cross-Validation} and Generalized {Cross-Validation}: Discrete
  Index Set},
  author={Li, Ker-Chau},
  journal={The Annals of Statistics},
  volume    =  15,
  pages={958--975},
  year={1987},
  publisher = "Institute of Mathematical Statistics"
}

@article{shao1997asymptotic,
  title={An asymptotic theory for linear model selection},
  author={Shao, Jun},
  journal={Statistica Sinica},
  volume    =  7,
  number    =  2,
  pages     = "221--242",
  year      =  1997,
  publisher = "Institute of Statistical Science, Academia Sinica",
}
@book{green1993nonparametric,
  title={Nonparametric regression and generalized linear models: a roughness penalty approach},
  author={Green, Peter J and Silverman, Bernard W},
  year={1993},
  publisher={CRC Press}
}
@book{zhang2017matrix,
  title={Matrix analysis and applications},
  author={Zhang, Xian-Da},
  year={2017},
  publisher={Cambridge University Press}
}
@book{de1975local,
  title={On local linear functionals which vanish at all B-splines but one},
  author={De Boor, Carl},
  year={1975},
  publisher={Mathematics Research Center, University of Wisconsin}
}
@article{buja1989linear,
  title={Linear smoothers and additive models},
  author={Buja, Andreas and Hastie, Trevor and Tibshirani, Robert},
  journal={The Annals of Statistics},
  pages={453--510},
volume = {17},
  year={1989},
  publisher={Institute of Mathematical Statistics}
}
@article{heckman2012theory,
  title={The theory and application of penalized methods or Reproducing Kernel Hilbert Spaces made easy},
  author={Heckman, Nancy and others},
  journal={Statistics Surveys},
  volume={6},
  pages={113--141},
  year={2012},
  publisher={The author, under a Creative Commons Attribution License}
}
@article{o1986automatic,
  title={Automatic smoothing of regression functions in generalized linear models},
  author={O'sullivan, Finbarr and Yandell, Brian S and Raynor Jr, William J},
  journal={Journal of the American Statistical Association},
  volume={81},
  number={393},
  pages={96--103},
  year={1986},
  publisher={Taylor \& Francis Group}
}
@book{hastie1990generalized,
  title={Generalized additive models},
  author={Hastie, Trevor and Tibshirani, Robert},
edition = {2},
  year={1990},
  publisher={Chapman and Hall/CRC}
}
@article{feng2017gradient,
  title     = "Gradient-based Regularization Parameter Selection for Problems
               With Nonsmooth Penalty Functions",
  author    = "Feng, Jean and Simon, Noah",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  27,
  number    =  2,
  pages     = "426--435",
  year      =  2018
}


@BOOK{van1996weak,
  title  = "Weak Convergence and Empirical Processes: With Applications to
            Statistics",
  author = "Vaart, Aad W van der and Wellner, Jon A",
  series = "Springer Series in Statistics",
  year   =  1996
}

@article{horowitz2006optimal,
  title     = "Optimal estimation in additive regression models",
  author    = "Horowitz, Joel and Klemel{\"a}, Jussi and Mammen, Enno",
  journal   = "Bernoulli",
  publisher = "Bernoulli Society for Mathematical Statistics and Probability",
  volume    =  12,
  number    =  2,
  pages     = "271--298",
  month     =  apr,
  year      =  2006,
}

@article{van2015penalized,
  title={Penalized least squares estimation in the additive model with different smoothness for the components},
  author={van de Geer, Sara and Muro, Alan},
  journal={Journal of Statistical Planning and Inference},
  volume={162},
  pages={43--61},
  year={2015},
  publisher={Elsevier}
}
@article{hebiri2011smooth,
  title     = "The {Smooth-Lasso} and other L1+L2-penalized methods",
  author    = "Hebiri, Mohamed and van de Geer, Sara",
  journal   = "Electron. J. Stat.",
  publisher = "The Institute of Mathematical Statistics and the Bernoulli
               Society",
  volume    =  5,
  pages     = "1184--1226",
  year      =  2011,
}



@article{bunea2008honest,
  title     = "Honest variable selection in linear and logistic regression
               models via L1 and L1+L2 penalization",
  author    = "Bunea, Florentina",
  abstract  = "Project Euclid - mathematics and statistics online",
  journal   = "Electron. J. Stat.",
  publisher = "The Institute of Mathematical Statistics and the Bernoulli
               Society",
  volume    =  2,
  pages     = "1153--1194",
  year      =  2008,
}



@article{sadhanala2017additive,
  title={Additive Models with Trend Filtering},
  author={Sadhanala, Veeranjaneyulu and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1702.05037},
  year={2017}
}
@incollection{tikhomirov1993varepsilon,
  title={$\varepsilon$-entropy and $\varepsilon$-capacity of sets in functional spaces},
  author={Tikhomirov, VM},
  booktitle={Selected works of AN Kolmogorov},
  pages={86--170},
  year={1993},
  publisher={Springer}
}


